{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lion_img = cv2.imread(\"C:\\\\Users\\\\NANDHU\\\\Desktop\\\\lion.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the image was loaded successfully\n",
    "if lion_img is None:\n",
    "    print(\"Error: Image not found!\")\n",
    "else:\n",
    "    # Display the image in a window\n",
    "    cv2.imshow('Loaded Image', lion_img)\n",
    "\n",
    "    # Wait for a key press and close all windows\n",
    "    cv2.waitKey(1000)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 197, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get image dimensions (height, width, channels)\n",
    "height, width, channels = lion_img.shape\n",
    "height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 127\n"
     ]
    }
   ],
   "source": [
    "# Calculate center of the image\n",
    "center_x = width // 2\n",
    "center_y = height // 2\n",
    "print(center_x,center_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Image Manipulations\n",
    "   cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "   cv2.resize(image, (width, height))\n",
    "   cropping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(lion_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the grayscale image\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = cv2.resize(lion_img, (350, 450))  \n",
    "cv2.imshow('Resized Image', resized_image)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing line using mouse point\n",
    "\n",
    "# Initialize global variables\n",
    "points = []\n",
    "\n",
    "# Mouse callback function to get points\n",
    "def click_and_crop(event, x, y, flags, param):\n",
    "    global points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Append the point to the points list\n",
    "        points.append((x, y))\n",
    "        # Draw a circle at the point\n",
    "        cv2.circle(lion_img, (x, y), 5, (0, 255, 0), -1)  # Green circle\n",
    "        cv2.imshow(\"Image\", lion_img)\n",
    "        if len(points) == 2:  # Once 2 points are selected, draw the line\n",
    "            cv2.line(lion_img, points[0], points[1], (0, 255, 0), 3)\n",
    "            cv2.imshow(\"Image with Line\", lion_img)\n",
    "\n",
    "# Read the image\n",
    "lion_img = cv2.imread(\"C:\\\\Users\\\\NANDHU\\\\Desktop\\\\lion.jpg\")\n",
    "\n",
    "# Display the image and set up the mouse callback\n",
    "cv2.imshow(\"Image\", lion_img)\n",
    "cv2.setMouseCallback(\"Image\", click_and_crop)\n",
    "\n",
    "# Wait until 2 points are selected\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a green line from (50, 50) to (300, 300)\n",
    "cv2.line(lion_img, (60, 50), (200, 100), (0, 255, 0), 3)  # (B, G, R) format\n",
    "cv2.imshow('Line on Image', lion_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a red circle with center (200, 200) and radius 50\n",
    "cv2.circle(lion_img, (0, 80), 50, (0, 0, 255), 1)  # -1 for filled circle\n",
    "cv2.imshow('Circle on Image', lion_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the text \"OpenCV\" at position (50, 50)\n",
    "cv2.putText(lion_img, 'Lion', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "cv2.imshow('Text on Image', lion_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#cv2.putText(image, text, position, font, scale, color, thickness, lineType)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Filters\n",
    "*Blurring Images --> to reduce noise.. cv2.GaussianBlur(image, (kernel_width, kernel_height), sigmaX)\n",
    "kernel width, height to fix extent of blur, must be +ve odds(3,5,7...)\n",
    "sigmax --> controls amount of blur in horizontal direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian Blur with kernel size (5, 5)\n",
    "blurred_image = cv2.GaussianBlur(lion_img, (5, 5), 0)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny edge detection algorithm follows a multi-step process:\n",
    "Noise Reduction\n",
    "Gradient Calculation(change in intensity at each pixel)\n",
    "Double Thresholding --> Strong edges: Pixels with gradient magnitude above a high threshold.\n",
    "Weak edges: Pixels with gradient magnitude between a low and high threshold.\n",
    "Non-edges: Pixels with gradient magnitude below the low threshold.\n",
    "Edge Tracking by Hysteresis : the edges that are continuous and connected to strong edges are retained.\n",
    "Thresholds: define the range of gradient values that are considered edges. Adjusting these values allows for more or less sensitivity to edges.\n",
    "Preprocessing: It's important to apply Gaussian blur (or other noise reduction techniques) before using Canny, as noise can result in false edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(lion_img, 100, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#cv2.Canny(image, threshold1, threshold2): Detects edges in an image.\n",
    "#threshold1: The lower threshold for the gradient intensity.\n",
    "#threshold2: The upper threshold for the gradient intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #Thresholding\n",
    "Thresholding is used to create binary images, separating the objects from the background.\n",
    "cv2.threshold(image, threshold_value, max_value, thresholding_method): Applies the thresholding.\n",
    "Convert image to grayscale first\n",
    "It works by setting all pixel values above a certain threshold to one value (usually white), and all pixel values below the threshold to another value (usually black). \n",
    "cv2.threshold(image, threshold_value, max_value, thresholding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply binary threshold\n",
    "_, threshold_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Thresholded Image', threshold_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Contours\n",
    "Contours help to detect objects and boundaries in an image\n",
    "In image processing, a contour is a curve that joins all the continuous points along a boundary that have the same color or intensity\n",
    "Contours are essentially the outlines of objects or regions in an image.\n",
    "The image must be in a binary format (black and white)\n",
    "It is common to apply thresholding or edge detection (e.g., Canny edge detection) before using findContours()\n",
    "mode: Contour retrieval mode, which specifies how the contours should be retrieved.\n",
    "\n",
    "method: Contour approximation method.\n",
    "cv2.CHAIN_APPROX_SIMPLE: Compresses horizontal, vertical, and diagonal segments, and leaves only their end points. This is the most commonly used method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours\n",
    "contours, _ = cv2.findContours(threshold_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours\n",
    "cv2.drawContours(lion_img, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow('Contours', lion_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haar cascade for smile detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Haar Cascade models\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread(\"C:\\\\Users\\\\NANDHU\\\\Desktop\\\\smile.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale for easier processing\n",
    "cv2.imshow('Smile Image', image)\n",
    "cv2.imshow('Smile gray Image', gray)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "#scalefactor--> 1.1 to 1.3\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    #x,y -- co-ordinates of (top left corner)the face, w width, h height\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "#x + w, y + h ---> bottom right corner of rectangle\n",
    "#(255,0,0) --> color \n",
    "#2 --> thickness of rectangle border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    # Define the region of interest (ROI) for smile detection (only within the face)\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    \n",
    "    # Detect smiles within the ROI\n",
    "    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "    \n",
    "    # Draw rectangles around the smiles\n",
    "    for (sx, sy, sw, sh) in smiles:\n",
    "        cv2.rectangle(image, (x + sx, y + sy), (x + sx + sw, y + sy + sh), (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with face and smile detection\n",
    "cv2.imshow('Smile Detection', image)\n",
    "\n",
    "# Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_image = cv2.imread(\"C:\\\\Users\\\\NANDHU\\\\Desktop\\\\groupsmile.jpg\")\n",
    "g_gray = cv2.cvtColor(g_image, cv2.COLOR_BGR2GRAY) \n",
    "cv2.imshow('Smile Image', g_image)\n",
    "cv2.imshow('Smile gray Image', g_gray)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "faces = face_cascade.detectMultiScale(g_gray, scaleFactor=1.1, minNeighbors=5)\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(g_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    roi_gray = g_gray[y:y + h, x:x + w]\n",
    "    \n",
    "    smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "    \n",
    "    for (sx, sy, sw, sh) in smiles:\n",
    "        cv2.rectangle(g_image, (x + sx, y + sy), (x + sx + sw, y + sy + sh), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('Smile Detection', g_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real time smile detection using Haar cascade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webcam capture (0 is the default camera, use 1 for secondary cameras)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Exit the loop if there's an issue with capturing frames\n",
    "    \n",
    "    # Convert the frame to grayscale (Haar Cascades work with grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    # Loop over each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Define the region of interest (ROI) for smile detection (inside the face bounding box)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        \n",
    "        # Detect smiles in the face region\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25))\n",
    "        \n",
    "        # Loop over each detected smile and draw a rectangle around it\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(frame, (x + sx, y + sy), (x + sx + sw, y + sy + sh), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame with face and smile detection\n",
    "    cv2.imshow('Smile Detection', frame)\n",
    "    \n",
    "    # Break the loop when the user presses the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close any OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
